---
title: "Statistics 506- Problem Set #6"
author: "Garrett Pinkston"
format: pdf
editor: visual
---

## **Link to GitHub**

github: https://github.com/garrettpinkston2015/Computational-Methods

## **Stratified Bootstrapping**

If a sample has a categorical variable with small groups, bootstrapping can be tricky. Consider a situation where $n = 100$, but there is some categorical variable $g$ where $g = 1$ has only 2 observations.

In a single bootstrap resample of that data, there is a

$$\binom{98}{100} \approx 13\%$$

chance that the bootstrap sample does not include either observation from $g = 1$. This implies that if we are attempting to obtain a bootstrap estimate in group $g = 1$, 13% of the bootstrapped samples will have no observations from that group and thus will be unable to produce an estimate.

A way around this is to carry out stratified bootstrap: Instead of taking a sample with replacement of the whole sample, take separate bootstrap resamples within each strata, then combine those resamples to generate the bootstrap sample.

```{r}
library(DBI)
library(RSQLite)

# Specify the path to your SQLite database
db_path <- "/Users/garrettpinkston/Desktop/Michigan/STAT506/Data/lahman_1871-2022.sqlite"

# Connect to the database
lahman <- dbConnect(RSQLite::SQLite(), dbname = db_path)
```

Use the "lahman" data that we first introduced in SQL. In the statistical analysis of baseball statistics, one metric used to measure a player's performance is their **Range Factor**:

$$RF = 3 \frac{PO + A}{InnOuts}$$

Here, "PO" is putouts, "A" is assists, and "InnOuts" is the number of outs they were on the field for.

a)  Calculate the average $RF$ for each team in the `Fielding` table. Then, since we donâ€™t have a closed form for the standard deviation of this statistic, carry out a stratified bootstrap *by team* to estimate it. Do this out three ways:

    1.  Without any parallel processing

```{r}
library(dplyr)


# connect to database
db_path <- "/Users/garrettpinkston/Desktop/Michigan/STAT506/Data/lahman_1871-2022.sqlite"

lahman <- dbConnect(RSQLite::SQLite(), dbname = db_path)

fielding <- dbReadTable(lahman, "Fielding")

fielding <- fielding %>%
  filter(!is.na(PO), !is.na(A), !is.na(InnOuts), InnOuts > 0) %>%
  mutate(RF = 3 * (PO + A) / InnOuts)

team_avg_rf <- fielding %>%
  group_by(teamID) %>%
  summarise(avg_RF = mean(RF, na.rm = TRUE))

stratified_bootstrap <- function(data, strata_col, n_boot) {
  results <- vector("list", n_boot)
  
  for (i in seq_len(n_boot)) {
    boot_sample <- data %>%
      group_by_at(strata_col) %>%
      group_modify(~ .x[sample(nrow(.x), replace = TRUE), ]) %>%
      ungroup()
    
    boot_avg_rf <- boot_sample %>%
      group_by(teamID) %>%
      summarise(avg_RF = mean(RF, na.rm = TRUE))
    
    results[[i]] <- boot_avg_rf
  }
  
  bind_rows(results, .id = "bootstrap_iteration")
}

n_boot <- 1000
boot_results <- stratified_bootstrap(fielding, "teamID", n_boot)

boot_sd <- boot_results %>%
  group_by(teamID) %>%
  summarise(sd_RF = sd(avg_RF, na.rm = TRUE))

final_results_normal <- team_avg_rf %>%
  left_join(boot_sd, by = "teamID")

print(final_results_normal)

dbDisconnect(lahman)
```


    2.  Using parallel processing with the parallel package.


```{r}
library(dplyr)
library(DBI)
library(RSQLite)
library(parallel)

# connect to database
db_path <- "/Users/garrettpinkston/Desktop/Michigan/STAT506/Data/lahman_1871-2022.sqlite"
lahman <- dbConnect(SQLite(), dbname = db_path)

fielding <- dbReadTable(lahman, "Fielding") %>%
  filter(!is.na(PO), !is.na(A), !is.na(InnOuts), InnOuts > 0) %>%
  mutate(RF = 3 * (PO + A) / InnOuts)

team_avg_rf <- fielding %>%
  group_by(teamID) %>%
  summarise(avg_RF = mean(RF, na.rm = TRUE))

bootstrap_iter <- function(data) {
  library(dplyr)
  data %>%
    group_by(teamID) %>%
    group_modify(~ .x[sample(nrow(.x), replace = TRUE), ]) %>%
    summarise(avg_RF = mean(RF, na.rm = TRUE))
}

parallel_bootstrap <- function(data, n_boot) {
  n_cores <- detectCores() - 1  # Use all but one core
  cl <- makeCluster(n_cores)
  
  clusterExport(cl, c("data", "bootstrap_iter"), envir = environment())
  
  clusterEvalQ(cl, library(dplyr))
  
  results <- parLapply(cl, 1:n_boot, function(i) bootstrap_iter(data))
  stopCluster(cl)  
  
  bind_rows(results, .id = "bootstrap_iteration")
}

n_boot <- 1000
boot_results <- parallel_bootstrap(fielding, n_boot)

boot_sd <- boot_results %>%
  group_by(teamID) %>%
  summarise(sd_RF = sd(avg_RF, na.rm = TRUE))

final_results_parallel <- team_avg_rf %>%
  left_join(boot_sd, by = "teamID")

print(final_results_parallel)

dbDisconnect(lahman)

```



    3.  Using futures with the future package.

```{r}
library(dplyr)
library(DBI)
library(RSQLite)
library(future)
library(furrr) 

# connect to database
db_path <- "/Users/garrettpinkston/Desktop/Michigan/STAT506/Data/lahman_1871-2022.sqlite"
lahman <- dbConnect(SQLite(), dbname = db_path)

fielding <- dbReadTable(lahman, "Fielding") %>%
  filter(!is.na(PO), !is.na(A), !is.na(InnOuts), InnOuts > 0) %>%
  mutate(RF = 3 * (PO + A) / InnOuts)

team_avg_rf <- fielding %>%
  group_by(teamID) %>%
  summarise(avg_RF = mean(RF, na.rm = TRUE))

bootstrap_iter <- function(data) {
  data %>%
    group_by(teamID) %>%
    group_modify(~ .x[sample(nrow(.x), replace = TRUE), ]) %>%
    summarise(avg_RF = mean(RF, na.rm = TRUE))
}

plan(multisession) 

n_boot <- 1000
boot_results <- future_map_dfr(1:n_boot, ~ bootstrap_iter(fielding), .options = furrr_options(seed = TRUE))

boot_sd <- boot_results %>%
  group_by(teamID) %>%
  summarise(sd_RF = sd(avg_RF, na.rm = TRUE))

final_result_future <- team_avg_rf %>%
  left_join(boot_sd, by = "teamID")

print(final_result_future)

dbDisconnect(lahman)

```


b)  Generate a table showing the estimated RF and associated standard errors for the teams with the 10 highest RF from the three approaches.


```{r}

#normalize names for consistency
results_non_parallel <- final_results_normal  
results_parallel <- final_results_parallel     
results_future <- final_result_future        

results_non_parallel <- results_non_parallel %>% mutate(method = "Non-Parallel")
results_parallel <- results_parallel %>% mutate(method = "Parallel")
results_future <- results_future %>% mutate(method = "Future")
all_results <- bind_rows(results_non_parallel, results_parallel, results_future)

top_teams <- all_results %>%
  arrange(desc(avg_RF)) %>%
  group_by(method) %>%
  slice_head(n = 10) %>%
  ungroup()

library(knitr)
library(kableExtra)

top_teams_table <- top_teams %>%
  select(teamID, avg_RF, sd_RF, method) %>%
  arrange(method, desc(avg_RF)) %>%
  kable(
    format = "latex",  
    booktabs = TRUE,  
    col.names = c("Team ID", "Average RF", "Standard Error", "Method"),
    caption = "Top 10 Teams with Highest RF Across Methods"
  ) %>%
  kable_styling(latex_options = c("striped", "hold_position"))

top_teams_table
```

c) Report and discuss the performance difference between the versions:

The future method generally produces slightly lower or comparable standard errors for most teams, which shows better consistency in bootstrap sampling across iterations since it handles random seeds and parallelization better. On the other hand, the non-parallel method shows slightly higher standard errors in some cases compared to future, potentially due to computational limitations or slight inconsistencies in handling random sampling over a long single-threaded process. Last, the parallel method sometimes shows the highest standard errors (e.g., MLU, KEO), which could be attributed to variations in random sampling or differences in how workers handle bootstrap iterations in a distributed environment.

The three methods analyzed produce pretty consistent results in terms of average RF and team rankings, but their efficiency and reliability differ. The future approach stands out as the best overall method for handling stratified bootstrapping for this problem.


